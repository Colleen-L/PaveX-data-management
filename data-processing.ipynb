{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 4,
>>>>>>> 7d4297e0b10ab731eaca8054b3cf8a8cb5bb05ab
   "id": "c04a10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# obtains timestamp\n",
    "def get_timestamp(filename):\n",
    "  try:\n",
    "    # takes the part before the dot\n",
    "    ts_str = filename.split('.')[0]\n",
    "    # converts to float\n",
    "    ts_float = float(ts_str)\n",
    "    # converts to UTC datetime\n",
    "    return datetime.fromtimestamp(ts_float, tz=timezone.utc)\n",
    "  except Exception:\n",
    "    return None\n",
    "  \n",
    "import json\n",
    "import os\n",
    "\n",
    "json_folder = \"data/\"\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith(\".json\")]\n",
    "\n",
    "# stores data for later conversion into dataframe\n",
    "segments = []\n",
    "drives = []\n",
    "cameras = []\n",
    "images = []\n",
    "camera_images = []\n",
    "categories = []\n",
    "image_categories = []\n",
    "\n",
    "# id maps\n",
    "segment_id_map = {}\n",
    "drive_id_map = {}\n",
    "camera_id_map = {}\n",
    "image_id_map = {}\n",
    "category_id_map = {}\n",
    "\n",
    "# counters for the id (beneficial for conversion to psql)\n",
    "segment_counter = 1\n",
    "drive_counter = 1\n",
    "camera_counter = 1\n",
    "image_counter = 1\n",
    "cam_img_counter = 1\n",
    "category_counter = 1\n",
    "img_cat_counter = 1\n",
    "\n",
    "# keeps track of missing classifications\n",
    "missing_classifications = []"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 5,
>>>>>>> 7d4297e0b10ab731eaca8054b3cf8a8cb5bb05ab
   "id": "7c1a2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_file in json_files:\n",
    "    file_path = os.path.join(json_folder, json_file)\n",
    "    \n",
    "    # loads the JSON\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for segment_name, segment_data in data.items():\n",
    "      # assign unique ID to each segment\n",
    "      if segment_name not in segment_id_map:\n",
    "        segment_id_map[segment_name] = segment_counter\n",
    "        segment_counter += 1\n",
    "      seg_pk = segment_id_map[segment_name]\n",
    "\n",
    "      # track timestamps for the segments\n",
    "      segment_timestamps = []\n",
    "\n",
    "      for drive_name, drive_data in segment_data.items():\n",
    "        # obtaining unique drive_id\n",
    "        drive_key = (segment_name, drive_name)\n",
    "        if drive_key not in drive_id_map:\n",
    "          drive_id_map[drive_key] = drive_counter\n",
    "          drive_counter += 1\n",
    "        drive_pk = drive_id_map[drive_key]\n",
    "\n",
    "        # saves dir_day and dir_pass\n",
    "        dir_day = drive_data.get('dir_day')\n",
    "        dir_pass = drive_data.get('dir_pass')\n",
    "        # tracks timestampes\n",
    "        drive_timestamps = []\n",
    "\n",
    "        # add to Cameras table\n",
    "        # finds all keys starting with 'cam'\n",
    "        camera_keys = [k for k in drive_data.keys() if k.startswith('cam')]\n",
    "        # obtains cam info and assign unique camera id\n",
    "        for cam_name in camera_keys:\n",
    "          cam_key = f\"{drive_name}_{cam_name}_{segment_name}\"\n",
    "          if cam_key not in camera_id_map:\n",
    "            camera_id_map[cam_key] = camera_counter\n",
    "            camera_counter += 1\n",
    "          cam_pk = camera_id_map[cam_key]\n",
    "\n",
    "          cameras.append({\n",
    "            \"Camera_ID\": cam_pk,\n",
    "            \"Drive_ID\": drive_pk,\n",
    "            \"Name\": cam_name\n",
    "          })\n",
    "\n",
    "          cam_data = drive_data[cam_name]\n",
    "\n",
    "          # process images by color, depth\n",
    "          for img_type in ['color', 'depth']:\n",
    "            if img_type in cam_data:\n",
    "              for filename in cam_data[img_type]:\n",
    "                if filename not in image_id_map:\n",
    "                  image_id_map[filename] = image_counter\n",
    "                  ts = get_timestamp(filename)\n",
    "                  images.append({\n",
    "                    \"Image_ID\": image_counter,\n",
    "                    \"Filename\": filename,\n",
    "                    \"Type\": img_type,\n",
    "                    \"Timestamp\": ts\n",
    "                  })\n",
    "                  \n",
    "                  # track timestamps\n",
    "                  if ts:\n",
    "                    segment_timestamps.append(ts)\n",
    "                    drive_timestamps.append(ts)\n",
    "                  \n",
    "                  image_counter += 1\n",
    "                  \n",
    "                image_pk = image_id_map[filename]\n",
    "                \n",
    "                camera_images.append({\n",
    "                  \"ID\": cam_img_counter,\n",
    "                  \"Camera_ID\": cam_pk,\n",
    "                  \"Image_ID\": image_pk\n",
    "                })\n",
    "                cam_img_counter += 1\n",
    "\n",
    "          # process classifications\n",
    "          if \"Classification_Swin\" in cam_data:\n",
    "            for category_name, file_list in cam_data[\"Classification_Swin\"].items():\n",
    "              # obtains classifcation info and assigns unique id\n",
    "              if category_name not in category_id_map:\n",
    "                category_id_map[category_name] = category_counter\n",
    "                categories.append({\n",
    "                  \"Category_ID\": category_counter,\n",
    "                  \"Name\": category_name\n",
    "                })\n",
    "                category_counter += 1\n",
    "              cat_pk = category_id_map[category_name]\n",
    "              \n",
    "              for filename in file_list:\n",
    "                # extracts filename\n",
    "                filename_only = filename.split('\\\\')[-1]\n",
    "                \n",
    "                if filename_only in image_id_map:\n",
    "                  image_pk = image_id_map[filename_only]\n",
    "                  image_categories.append({\n",
    "                    \"ID\": img_cat_counter,\n",
    "                    \"Image_ID\": image_pk,\n",
    "                    \"Category_ID\": cat_pk,\n",
    "                    \"Confidence\": None\n",
    "                  })\n",
    "                  img_cat_counter += 1\n",
    "                else:\n",
    "                  missing_classifications.append({\n",
    "                    \"filename\": filename_only,\n",
    "                    \"category\": category_name,\n",
    "                    \"segment\": segment_name,\n",
    "                    \"drive\": drive_name,\n",
    "                    \"camera\": cam_name\n",
    "                  })\n",
    "\n",
    "        # adds to Drives table\n",
    "        drives.append({\n",
    "          \"Drive_ID\": drive_pk,\n",
    "          \"Name\": drive_name,\n",
    "          \"Segment_ID\": seg_pk,\n",
    "          \"Dir_Day\": dir_day,\n",
    "          \"Dir_Pass\": dir_pass,\n",
    "          \"Time_Driven\": min(drive_timestamps) if drive_timestamps else None,\n",
    "          \"Source_File\": json_file\n",
    "        })\n",
    "\n",
    "      # adds to Segments\n",
    "      # using min of the timestamps\n",
    "      seg_time_recorded = min(segment_timestamps) if segment_timestamps else None\n",
    "      segments.append({\n",
    "        \"Segment_ID\": seg_pk,\n",
    "        \"Name\": segment_name,\n",
    "        \"Location\": \"Fort Wayne, IN\",\n",
    "        \"Date_Recorded\": seg_time_recorded.date() if seg_time_recorded else None,\n",
    "        \"Source_File\": json_file\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 6,
>>>>>>> 7d4297e0b10ab731eaca8054b3cf8a8cb5bb05ab
   "id": "89a4e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA SUMMARY\n",
      "============================================================\n",
      "Number of Files: 5\n",
      "Segments: 3446\n",
      "Drives: 4741\n",
      "Cameras: 9482\n",
      "Unique Images: 3844044\n",
      "Camera-Image Relationships: 3844272\n",
      "Categories: 8\n",
      "Image-Category Relationships: 2716277\n",
      "\n",
      "Images with classifications: 1921517\n",
      "Total color images: 1922028\n",
      "Classification coverage: 100.0%\n",
      "\n",
      "============================================================\n",
      "\n",
      "SEGMENTS\n",
      "   Segment_ID           Name        Location Date_Recorded  \\\n",
      "0           1   segment_7358  Fort Wayne, IN    2025-03-09   \n",
      "1           2   segment_7352  Fort Wayne, IN    2025-03-09   \n",
      "2           3   segment_7348  Fort Wayne, IN    2025-03-09   \n",
      "3           4   segment_7360  Fort Wayne, IN    2025-03-09   \n",
      "4           5  segment_26962  Fort Wayne, IN    2025-03-09   \n",
      "\n",
      "                                     Source_File  \n",
      "0  segments_data_round3_day1_classification.json  \n",
      "1  segments_data_round3_day1_classification.json  \n",
      "2  segments_data_round3_day1_classification.json  \n",
      "3  segments_data_round3_day1_classification.json  \n",
      "4  segments_data_round3_day1_classification.json  \n",
      "\n",
      "DRIVES (showing Segment_ID relationship)\n",
      "   Drive_ID     Name  Segment_ID Dir_Pass\n",
      "0         1  drive_0           1    pass0\n",
      "1         2  drive_0           2    pass0\n",
      "2         3  drive_0           3    pass0\n",
      "3         4  drive_0           4    pass0\n",
      "4         5  drive_0           5    pass0\n",
      "5         6  drive_0           6    pass0\n",
      "6         7  drive_0           7    pass0\n",
      "7         8  drive_0           8    pass0\n",
      "8         9  drive_0           9    pass0\n",
      "9        10  drive_0          10    pass0\n",
      "\n",
      "CAMERAS\n",
      "   Camera_ID  Drive_ID  Name\n",
      "0          1         1  cam1\n",
      "1          2         1  cam2\n",
      "2          3         2  cam1\n",
      "3          4         2  cam2\n",
      "4          5         3  cam1\n",
      "\n",
      "IMAGES\n",
      "   Image_ID               Filename   Type                 Timestamp\n",
      "0         1  1741543782.793046.jpg  color 2025-03-09 18:09:42+00:00\n",
      "1         2  1741543782.808574.jpg  color 2025-03-09 18:09:42+00:00\n",
      "2         3  1741543782.835759.jpg  color 2025-03-09 18:09:42+00:00\n",
      "3         4  1741543782.902475.jpg  color 2025-03-09 18:09:42+00:00\n",
      "4         5  1741543782.969288.jpg  color 2025-03-09 18:09:42+00:00\n",
      "\n",
      "CAMERA_IMAGES\n",
      "   ID  Camera_ID  Image_ID\n",
      "0   1          1         1\n",
      "1   2          1         2\n",
      "2   3          1         3\n",
      "3   4          1         4\n",
      "4   5          1         5\n",
      "\n",
      "CATEGORIES\n",
      "   Category_ID          Name\n",
      "0            1     Alligator\n",
      "1            2        Health\n",
      "2            3  Longitudinal\n",
      "3            4       Manhole\n",
      "4            5     Openjoint\n",
      "\n",
      "IMAGE_CATEGORIES\n",
      "   ID  Image_ID  Category_ID Confidence\n",
      "0   1       216            1       None\n",
      "1   2       217            1       None\n",
      "2   3       218            1       None\n",
      "3   4       219            1       None\n",
      "4   5       241            1       None\n"
     ]
    }
   ],
   "source": [
    "# data validations\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of Files: {len(json_files)}\")\n",
    "print(f\"Segments: {len(segments)}\")\n",
    "print(f\"Drives: {len(drives)}\")\n",
    "print(f\"Cameras: {len(cameras)}\")\n",
    "print(f\"Unique Images: {len(images)}\")\n",
    "print(f\"Camera-Image Relationships: {len(camera_images)}\")\n",
    "print(f\"Categories: {len(categories)}\")\n",
    "print(f\"Image-Category Relationships: {len(image_categories)}\")\n",
    "\n",
    "# check classification coverage\n",
    "classified_image_ids = {ic['Image_ID'] for ic in image_categories}\n",
    "all_image_ids = {i['Image_ID'] for i in images}\n",
    "color_images = [i for i in images if i['Type'] == 'color']\n",
    "print(f\"\\nImages with classifications: {len(classified_image_ids)}\")\n",
    "print(f\"Total color images: {len(color_images)}\")\n",
    "# Fixed: add check to avoid division by zero\n",
    "if len(color_images) > 0:\n",
    "    print(f\"Classification coverage: {len(classified_image_ids)/len(color_images)*100:.1f}%\")\n",
    "else:\n",
    "    print(\"Classification coverage: N/A (no color images found)\")\n",
    "\n",
    "if missing_classifications:\n",
    "  print(f\"\\nWARNING: {len(missing_classifications)} classified images not found in color/depth lists\")\n",
    "  print(\"First 5 missing:\")\n",
    "  for miss in missing_classifications[:5]:\n",
    "    print(f\"  - {miss['filename']} ({miss['category']}) in {miss['segment']}/{miss['drive']}/{miss['camera']}\")\n",
    "  \n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# convert to dataframes\n",
    "segments_df = pd.DataFrame(segments)\n",
    "drives_df = pd.DataFrame(drives)\n",
    "cameras_df = pd.DataFrame(cameras)\n",
    "images_df = pd.DataFrame(images)\n",
    "camera_images_df = pd.DataFrame(camera_images)\n",
    "categories_df = pd.DataFrame(categories)\n",
    "image_categories_df = pd.DataFrame(image_categories)\n",
    "\n",
    "# preview\n",
    "print(\"\\nSEGMENTS\")\n",
    "print(segments_df.head())\n",
    "\n",
    "print(\"\\nDRIVES (showing Segment_ID relationship)\")\n",
    "print(drives_df[['Drive_ID', 'Name', 'Segment_ID', 'Dir_Pass']].head(10))\n",
    "\n",
    "print(\"\\nCAMERAS\")\n",
    "print(cameras_df.head())\n",
    "\n",
    "print(\"\\nIMAGES\")\n",
    "print(images_df.head())\n",
    "\n",
    "print(\"\\nCAMERA_IMAGES\")\n",
    "print(camera_images_df.head())\n",
    "\n",
    "print(\"\\nCATEGORIES\")\n",
    "print(categories_df.head())\n",
    "\n",
    "print(\"\\nIMAGE_CATEGORIES\")\n",
    "print(image_categories_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9ea70",
   "metadata": {},
   "source": [
    "CONNECTING DATAFRAMES TO PSQL (NEON TECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86524246",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "Expected string or URL object, got None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArgumentError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m conn_str = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mNEON_CONNECTION_STR\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m engine = \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m segments_df.to_sql(\u001b[33m\"\u001b[39m\u001b[33msegments\u001b[39m\u001b[33m\"\u001b[39m, engine, if_exists=\u001b[33m\"\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      8\u001b[39m drives_df.to_sql(\u001b[33m\"\u001b[39m\u001b[33mdrives\u001b[39m\u001b[33m\"\u001b[39m, engine, if_exists=\u001b[33m\"\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m, in \u001b[36mcreate_engine\u001b[39m\u001b[34m(url, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\sqlalchemy\\util\\deprecations.py:281\u001b[39m, in \u001b[36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[39m\u001b[34m(fn, *args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    275\u001b[39m         _warn_with_version(\n\u001b[32m    276\u001b[39m             messages[m],\n\u001b[32m    277\u001b[39m             versions[m],\n\u001b[32m    278\u001b[39m             version_warnings[m],\n\u001b[32m    279\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    280\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:564\u001b[39m, in \u001b[36mcreate_engine\u001b[39m\u001b[34m(url, **kwargs)\u001b[39m\n\u001b[32m    561\u001b[39m kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mempty_in_strategy\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    563\u001b[39m \u001b[38;5;66;03m# create url.URL object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m u = \u001b[43m_url\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m u, plugins, kwargs = u._instantiate_plugins(kwargs)\n\u001b[32m    568\u001b[39m entrypoint = u._get_entrypoint()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\url.py:860\u001b[39m, in \u001b[36mmake_url\u001b[39m\u001b[34m(name_or_url)\u001b[39m\n\u001b[32m    856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_url(name_or_url)\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_url, URL) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[32m    858\u001b[39m     name_or_url, \u001b[33m\"\u001b[39m\u001b[33m_sqla_is_testing_if_this_is_a_mock_object\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    859\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ArgumentError(\n\u001b[32m    861\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected string or URL object, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_or_url\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    862\u001b[39m     )\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    864\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m name_or_url\n",
      "\u001b[31mArgumentError\u001b[39m: Expected string or URL object, got None"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "conn_str = os.getenv(\"NEON_CONNECTION_STR\")\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "segments_df.to_sql(\"segments\", engine, if_exists=\"append\", index=False)\n",
    "drives_df.to_sql(\"drives\", engine, if_exists=\"append\", index=False)\n",
    "cameras_df.to_sql(\"cameras\", engine, if_exists=\"append\", index=False)\n",
    "images_df.to_sql(\"images\", engine, if_exists=\"append\", index=False)\n",
    "camera_images_df.to_sql(\"camera_images\", engine, if_exists=\"append\", index=False)\n",
    "categories_df.to_sql(\"categories\", engine, if_exists=\"append\", index=False)\n",
    "#image_categories_df.to_sql(\"image_categories\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "# stopped processing due to reaching maximum neon tech project storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceadf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_segments = pd.read_sql(\"SELECT * FROM segments LIMIT 10;\", engine)\n",
    "check_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "def clear_db():\n",
    "  with engine.begin() as conn:\n",
    "    # removes all tables\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS segments\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS cameras\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS categories\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS drives\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS image_categories\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS images\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS camera_images\"))\n",
    "    # automatically commits at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f5b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b67b804",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.13.7"
=======
   "version": "3.13.2"
>>>>>>> 7d4297e0b10ab731eaca8054b3cf8a8cb5bb05ab
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
