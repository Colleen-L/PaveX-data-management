{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c04a10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# obtains timestamp\n",
    "def get_timestamp(filename):\n",
    "  try:\n",
    "    # takes the part before the dot\n",
    "    ts_str = filename.split('.')[0]\n",
    "    # converts to float\n",
    "    ts_float = float(ts_str)\n",
    "    # converts to UTC datetime\n",
    "    return datetime.fromtimestamp(ts_float, tz=timezone.utc)\n",
    "  except Exception:\n",
    "    return None\n",
    "  \n",
    "import json\n",
    "import os\n",
    "\n",
    "json_folder = \"data/\"\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith(\".json\")]\n",
    "\n",
    "# stores data for later conversion into dataframe\n",
    "segments = []\n",
    "drives = []\n",
    "cameras = []\n",
    "images = []\n",
    "camera_images = []\n",
    "categories = []\n",
    "image_categories = []\n",
    "\n",
    "# id maps\n",
    "segment_id_map = {}\n",
    "drive_id_map = {}\n",
    "camera_id_map = {}\n",
    "image_id_map = {}\n",
    "category_id_map = {}\n",
    "\n",
    "# counters for the id (beneficial for conversion to psql)\n",
    "segment_counter = 1\n",
    "drive_counter = 1\n",
    "camera_counter = 1\n",
    "image_counter = 1\n",
    "cam_img_counter = 1\n",
    "category_counter = 1\n",
    "img_cat_counter = 1\n",
    "\n",
    "# keeps track of missing classifications\n",
    "missing_classifications = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c1a2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_file in json_files:\n",
    "    file_path = os.path.join(json_folder, json_file)\n",
    "    \n",
    "    # loads the JSON\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for segment_name, segment_data in data.items():\n",
    "      # assign unique ID to each segment\n",
    "      if segment_name not in segment_id_map:\n",
    "        segment_id_map[segment_name] = segment_counter\n",
    "        segment_counter += 1\n",
    "      seg_pk = segment_id_map[segment_name]\n",
    "\n",
    "      # track timestamps for the segments\n",
    "      segment_timestamps = []\n",
    "\n",
    "      for drive_name, drive_data in segment_data.items():\n",
    "        # obtaining unique drive_id\n",
    "        drive_key = (segment_name, drive_name)\n",
    "        if drive_key not in drive_id_map:\n",
    "          drive_id_map[drive_key] = drive_counter\n",
    "          drive_counter += 1\n",
    "        drive_pk = drive_id_map[drive_key]\n",
    "\n",
    "        # saves dir_day and dir_pass\n",
    "        dir_day = drive_data.get('dir_day')\n",
    "        dir_pass = drive_data.get('dir_pass')\n",
    "        # tracks timestampes\n",
    "        drive_timestamps = []\n",
    "\n",
    "        # add to Cameras table\n",
    "        # finds all keys starting with 'cam'\n",
    "        camera_keys = [k for k in drive_data.keys() if k.startswith('cam')]\n",
    "        # obtains cam info and assign unique camera id\n",
    "        for cam_name in camera_keys:\n",
    "          cam_key = f\"{drive_name}_{cam_name}_{segment_name}\"\n",
    "          if cam_key not in camera_id_map:\n",
    "            camera_id_map[cam_key] = camera_counter\n",
    "            camera_counter += 1\n",
    "          cam_pk = camera_id_map[cam_key]\n",
    "\n",
    "          cameras.append({\n",
    "            \"Camera_ID\": cam_pk,\n",
    "            \"Drive_ID\": drive_pk,\n",
    "            \"Name\": cam_name\n",
    "          })\n",
    "\n",
    "          cam_data = drive_data[cam_name]\n",
    "\n",
    "          # process images by color, depth\n",
    "          for img_type in ['color', 'depth']:\n",
    "            if img_type in cam_data:\n",
    "              for filename in cam_data[img_type]:\n",
    "                if filename not in image_id_map:\n",
    "                  image_id_map[filename] = image_counter\n",
    "                  ts = get_timestamp(filename)\n",
    "                  images.append({\n",
    "                    \"Image_ID\": image_counter,\n",
    "                    \"Filename\": filename,\n",
    "                    \"Type\": img_type,\n",
    "                    \"Timestamp\": ts\n",
    "                  })\n",
    "                  \n",
    "                  # track timestamps\n",
    "                  if ts:\n",
    "                    segment_timestamps.append(ts)\n",
    "                    drive_timestamps.append(ts)\n",
    "                  \n",
    "                  image_counter += 1\n",
    "                  \n",
    "                image_pk = image_id_map[filename]\n",
    "                \n",
    "                camera_images.append({\n",
    "                  \"ID\": cam_img_counter,\n",
    "                  \"Camera_ID\": cam_pk,\n",
    "                  \"Image_ID\": image_pk\n",
    "                })\n",
    "                cam_img_counter += 1\n",
    "\n",
    "          # process classifications\n",
    "          if \"Classification_Swin\" in cam_data:\n",
    "            for category_name, file_list in cam_data[\"Classification_Swin\"].items():\n",
    "              # obtains classifcation info and assigns unique id\n",
    "              if category_name not in category_id_map:\n",
    "                category_id_map[category_name] = category_counter\n",
    "                categories.append({\n",
    "                  \"Category_ID\": category_counter,\n",
    "                  \"Name\": category_name\n",
    "                })\n",
    "                category_counter += 1\n",
    "              cat_pk = category_id_map[category_name]\n",
    "              \n",
    "              for filename in file_list:\n",
    "                # extracts filename\n",
    "                filename_only = filename.split('\\\\')[-1]\n",
    "                \n",
    "                if filename_only in image_id_map:\n",
    "                  image_pk = image_id_map[filename_only]\n",
    "                  image_categories.append({\n",
    "                    \"ID\": img_cat_counter,\n",
    "                    \"Image_ID\": image_pk,\n",
    "                    \"Category_ID\": cat_pk,\n",
    "                    \"Confidence\": None\n",
    "                  })\n",
    "                  img_cat_counter += 1\n",
    "                else:\n",
    "                  missing_classifications.append({\n",
    "                    \"filename\": filename_only,\n",
    "                    \"category\": category_name,\n",
    "                    \"segment\": segment_name,\n",
    "                    \"drive\": drive_name,\n",
    "                    \"camera\": cam_name\n",
    "                  })\n",
    "\n",
    "        # adds to Drives table\n",
    "        drives.append({\n",
    "          \"Drive_ID\": drive_pk,\n",
    "          \"Name\": drive_name,\n",
    "          \"Segment_ID\": seg_pk,\n",
    "          \"Dir_Day\": dir_day,\n",
    "          \"Dir_Pass\": dir_pass,\n",
    "          \"Time_Driven\": min(drive_timestamps) if drive_timestamps else None,\n",
    "          \"Source_File\": json_file\n",
    "        })\n",
    "\n",
    "      # adds to Segments\n",
    "      # using min of the timestamps\n",
    "      seg_time_recorded = min(segment_timestamps) if segment_timestamps else None\n",
    "      segments.append({\n",
    "        \"Segment_ID\": seg_pk,\n",
    "        \"Name\": segment_name,\n",
    "        \"Location\": \"Fort Wayne, IN\",\n",
    "        \"Date_Recorded\": seg_time_recorded.date() if seg_time_recorded else None,\n",
    "        \"Source_File\": json_file\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89a4e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA SUMMARY\n",
      "============================================================\n",
      "Number of Files: 5\n",
      "Segments: 3446\n",
      "Drives: 4741\n",
      "Cameras: 9482\n",
      "Unique Images: 3844044\n",
      "Camera-Image Relationships: 3844272\n",
      "Categories: 8\n",
      "Image-Category Relationships: 2716277\n",
      "\n",
      "Images with classifications: 1921517\n",
      "Total color images: 1922028\n",
      "Classification coverage: 100.0%\n",
      "\n",
      "============================================================\n",
      "\n",
      "SEGMENTS\n",
      "   Segment_ID           Name        Location Date_Recorded  \\\n",
      "0           1  segment_12818  Fort Wayne, IN    2025-03-12   \n",
      "1           2  segment_11788  Fort Wayne, IN    2025-03-12   \n",
      "2           3  segment_12820  Fort Wayne, IN    2025-03-12   \n",
      "3           4  segment_12826  Fort Wayne, IN    2025-03-12   \n",
      "4           5  segment_11776  Fort Wayne, IN    2025-03-12   \n",
      "\n",
      "                                       Source_File  \n",
      "0  segments_data_round3_day4_classification_1.json  \n",
      "1  segments_data_round3_day4_classification_1.json  \n",
      "2  segments_data_round3_day4_classification_1.json  \n",
      "3  segments_data_round3_day4_classification_1.json  \n",
      "4  segments_data_round3_day4_classification_1.json  \n",
      "\n",
      "DRIVES (showing Segment_ID relationship)\n",
      "   Drive_ID     Name  Segment_ID Dir_Pass\n",
      "0         1  drive_0           1    pass0\n",
      "1         2  drive_1           1    pass0\n",
      "2         3  drive_0           2    pass0\n",
      "3         4  drive_1           2    pass0\n",
      "4         5  drive_0           3    pass0\n",
      "5         6  drive_0           4    pass0\n",
      "6         7  drive_1           4    pass0\n",
      "7         8  drive_0           5    pass0\n",
      "8         9  drive_1           5    pass0\n",
      "9        10  drive_0           6    pass0\n",
      "\n",
      "CAMERAS\n",
      "   Camera_ID  Drive_ID  Name\n",
      "0          1         1  cam1\n",
      "1          2         1  cam2\n",
      "2          3         2  cam1\n",
      "3          4         2  cam2\n",
      "4          5         3  cam1\n",
      "\n",
      "IMAGES\n",
      "   Image_ID               Filename   Type                 Timestamp\n",
      "0         1  1741791371.056808.jpg  color 2025-03-12 14:56:11+00:00\n",
      "1         2  1741791371.123908.jpg  color 2025-03-12 14:56:11+00:00\n",
      "2         3  1741791371.190300.jpg  color 2025-03-12 14:56:11+00:00\n",
      "3         4  1741791371.257042.jpg  color 2025-03-12 14:56:11+00:00\n",
      "4         5  1741791371.323524.jpg  color 2025-03-12 14:56:11+00:00\n",
      "\n",
      "CAMERA_IMAGES\n",
      "   ID  Camera_ID  Image_ID\n",
      "0   1          1         1\n",
      "1   2          1         2\n",
      "2   3          1         3\n",
      "3   4          1         4\n",
      "4   5          1         5\n",
      "\n",
      "CATEGORIES\n",
      "   Category_ID          Name\n",
      "0            1     Alligator\n",
      "1            2        Health\n",
      "2            3  Longitudinal\n",
      "3            4       Manhole\n",
      "4            5     Openjoint\n",
      "\n",
      "IMAGE_CATEGORIES\n",
      "   ID  Image_ID  Category_ID Confidence\n",
      "0   1         1            2       None\n",
      "1   2         2            2       None\n",
      "2   3         3            2       None\n",
      "3   4         4            2       None\n",
      "4   5         5            2       None\n"
     ]
    }
   ],
   "source": [
    "# data validations\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of Files: {len(json_files)}\")\n",
    "print(f\"Segments: {len(segments)}\")\n",
    "print(f\"Drives: {len(drives)}\")\n",
    "print(f\"Cameras: {len(cameras)}\")\n",
    "print(f\"Unique Images: {len(images)}\")\n",
    "print(f\"Camera-Image Relationships: {len(camera_images)}\")\n",
    "print(f\"Categories: {len(categories)}\")\n",
    "print(f\"Image-Category Relationships: {len(image_categories)}\")\n",
    "\n",
    "# check classification coverage\n",
    "classified_image_ids = {ic['Image_ID'] for ic in image_categories}\n",
    "all_image_ids = {i['Image_ID'] for i in images}\n",
    "color_images = [i for i in images if i['Type'] == 'color']\n",
    "print(f\"\\nImages with classifications: {len(classified_image_ids)}\")\n",
    "print(f\"Total color images: {len(color_images)}\")\n",
    "print(f\"Classification coverage: {len(classified_image_ids)/len(color_images)*100:.1f}%\")\n",
    "\n",
    "if missing_classifications:\n",
    "  print(f\"\\nWARNING: {len(missing_classifications)} classified images not found in color/depth lists\")\n",
    "  print(\"First 5 missing:\")\n",
    "  for miss in missing_classifications[:5]:\n",
    "    print(f\"  - {miss['filename']} ({miss['category']}) in {miss['segment']}/{miss['drive']}/{miss['camera']}\")\n",
    "  \n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# convert to dataframes\n",
    "segments_df = pd.DataFrame(segments)\n",
    "drives_df = pd.DataFrame(drives)\n",
    "cameras_df = pd.DataFrame(cameras)\n",
    "images_df = pd.DataFrame(images)\n",
    "camera_images_df = pd.DataFrame(camera_images)\n",
    "categories_df = pd.DataFrame(categories)\n",
    "image_categories_df = pd.DataFrame(image_categories)\n",
    "\n",
    "# preview\n",
    "print(\"\\nSEGMENTS\")\n",
    "print(segments_df.head())\n",
    "\n",
    "print(\"\\nDRIVES (showing Segment_ID relationship)\")\n",
    "print(drives_df[['Drive_ID', 'Name', 'Segment_ID', 'Dir_Pass']].head(10))\n",
    "\n",
    "print(\"\\nCAMERAS\")\n",
    "print(cameras_df.head())\n",
    "\n",
    "print(\"\\nIMAGES\")\n",
    "print(images_df.head())\n",
    "\n",
    "print(\"\\nCAMERA_IMAGES\")\n",
    "print(camera_images_df.head())\n",
    "\n",
    "print(\"\\nCATEGORIES\")\n",
    "print(categories_df.head())\n",
    "\n",
    "print(\"\\nIMAGE_CATEGORIES\")\n",
    "print(image_categories_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e9ea70",
   "metadata": {},
   "source": [
    "CONNECTING DATAFRAMES TO PSQL (NEON TECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86524246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "conn_str = os.getenv(\"NEON_CONNECTION_STR\")\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "segments_df.to_sql(\"segments\", engine, if_exists=\"append\", index=False)\n",
    "drives_df.to_sql(\"drives\", engine, if_exists=\"append\", index=False)\n",
    "cameras_df.to_sql(\"cameras\", engine, if_exists=\"append\", index=False)\n",
    "images_df.to_sql(\"images\", engine, if_exists=\"append\", index=False)\n",
    "camera_images_df.to_sql(\"camera_images\", engine, if_exists=\"append\", index=False)\n",
    "categories_df.to_sql(\"categories\", engine, if_exists=\"append\", index=False)\n",
    "#image_categories_df.to_sql(\"image_categories\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "# stopped processing due to reaching maximum neon tech project storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ceadf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date_Recorded</th>\n",
       "      <th>Source_File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>segment_12818</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>segment_11788</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>segment_12820</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>segment_12826</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>segment_11776</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>segment_11777</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>segment_11774</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>segment_12822</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>segment_17682</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>segment_17684</td>\n",
       "      <td>Fort Wayne, IN</td>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>segments_data_round3_day4_classification_1.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment_ID           Name        Location Date_Recorded  \\\n",
       "0           1  segment_12818  Fort Wayne, IN    2025-03-12   \n",
       "1           2  segment_11788  Fort Wayne, IN    2025-03-12   \n",
       "2           3  segment_12820  Fort Wayne, IN    2025-03-12   \n",
       "3           4  segment_12826  Fort Wayne, IN    2025-03-12   \n",
       "4           5  segment_11776  Fort Wayne, IN    2025-03-12   \n",
       "5           6  segment_11777  Fort Wayne, IN    2025-03-12   \n",
       "6           7  segment_11774  Fort Wayne, IN    2025-03-12   \n",
       "7           8  segment_12822  Fort Wayne, IN    2025-03-12   \n",
       "8           9  segment_17682  Fort Wayne, IN    2025-03-12   \n",
       "9          10  segment_17684  Fort Wayne, IN    2025-03-12   \n",
       "\n",
       "                                       Source_File  \n",
       "0  segments_data_round3_day4_classification_1.json  \n",
       "1  segments_data_round3_day4_classification_1.json  \n",
       "2  segments_data_round3_day4_classification_1.json  \n",
       "3  segments_data_round3_day4_classification_1.json  \n",
       "4  segments_data_round3_day4_classification_1.json  \n",
       "5  segments_data_round3_day4_classification_1.json  \n",
       "6  segments_data_round3_day4_classification_1.json  \n",
       "7  segments_data_round3_day4_classification_1.json  \n",
       "8  segments_data_round3_day4_classification_1.json  \n",
       "9  segments_data_round3_day4_classification_1.json  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_segments = pd.read_sql(\"SELECT * FROM segments LIMIT 10;\", engine)\n",
    "check_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "def clear_db():\n",
    "  with engine.begin() as conn:\n",
    "    # removes all tables\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS segments\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS cameras\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS categories\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS drives\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS image_categories\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS images\"))\n",
    "    conn.execute(text(\"DROP TABLE IF EXISTS camera_images\"))\n",
    "    # automatically commits at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f5b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b67b804",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pavex_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
